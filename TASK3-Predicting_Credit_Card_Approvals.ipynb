{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI-x-pGfswFw",
        "outputId": "76097cec-d0dd-4009-e2cc-c90e9bd5a75c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial shape: (284807, 31)\n",
            "Numeric: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
            "Categorical: []\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "\n",
            "Accuracy: 0.9743864330606369\n",
            "\n",
            "Confusion Matrix:\n",
            " [[55413  1451]\n",
            " [    8    90]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56864\n",
            "           1       0.06      0.92      0.11        98\n",
            "\n",
            "    accuracy                           0.97     56962\n",
            "   macro avg       0.53      0.95      0.55     56962\n",
            "weighted avg       1.00      0.97      0.99     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 1. Load Data\n",
        "# ------------------------------------------------------\n",
        "df = pd.read_csv(\"creditcard.csv\")   # change path\n",
        "\n",
        "print(\"Initial shape:\", df.shape)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 2. Split features/target\n",
        "# ------------------------------------------------------\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 3. Identify numeric + categorical columns\n",
        "# ------------------------------------------------------\n",
        "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "print(\"Numeric:\", numeric_features)\n",
        "print(\"Categorical:\", categorical_features)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 4. Preprocessing pipelines\n",
        "# ------------------------------------------------------\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 5. Full pipeline (SMOTE → Preprocess → LR)\n",
        "# ------------------------------------------------------\n",
        "pipeline = ImbPipeline(\n",
        "    steps=[\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"smote\", SMOTE(random_state=42)),\n",
        "        (\"classifier\", LogisticRegression(max_iter=1000))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 6. Hyperparameter Optimization (GridSearchCV)\n",
        "# ------------------------------------------------------\n",
        "param_grid = {\n",
        "    \"classifier__penalty\": [\"l1\", \"l2\"],\n",
        "    \"classifier__C\": [0.01, 0.1, 1, 10],\n",
        "    \"classifier__solver\": [\"liblinear\"],   # required for L1\n",
        "    \"classifier__class_weight\": [None, \"balanced\"]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 7. Train-test split\n",
        "# ------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 8. Fit GridSearchCV\n",
        "# ------------------------------------------------------\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 9. Predict using best model\n",
        "# ------------------------------------------------------\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 10. Evaluation\n",
        "# ------------------------------------------------------\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tavn9SRj2RiZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}